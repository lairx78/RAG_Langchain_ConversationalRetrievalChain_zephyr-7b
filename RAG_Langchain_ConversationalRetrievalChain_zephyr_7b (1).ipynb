{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Chatbot using LangChain ConversationalRetrievalChain with Zephyr 7b gptq model"
      ],
      "metadata": {
        "id": "QqcIlSd4Vyk2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVcUBQykR9tU",
        "outputId": "9d24db90-5a13-4f0b-d57a-136963e2e5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chainlit\n",
            "  Downloading chainlit-1.0.504-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting auto-gptq\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.2) (4.66.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting aiofiles<24.0.0,>=23.1.0 (from chainlit)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting asyncer<0.0.3,>=0.0.2 (from chainlit)\n",
            "  Downloading asyncer-0.0.2-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit) (8.1.7)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting fastapi<0.111.0,>=0.110.1 (from chainlit)\n",
            "  Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-socketio<0.0.11,>=0.0.10 (from chainlit)\n",
            "  Downloading fastapi_socketio-0.0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from chainlit)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting httpx>=0.23.0 (from chainlit)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazify<0.5.0,>=0.4.0 (from chainlit)\n",
            "  Downloading Lazify-0.4.0-py2.py3-none-any.whl (3.1 kB)\n",
            "Collecting literalai==0.0.504 (from chainlit)\n",
            "  Downloading literalai-0.0.504.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit) (1.6.0)\n",
            "Collecting packaging>=20.0 (from transformers==4.37.2)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt<3.0.0,>=2.8.0 (from chainlit)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-dotenv<2.0.0,>=1.0.0 (from chainlit)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting python-graphql-client<0.5.0,>=0.4.3 (from chainlit)\n",
            "  Downloading python_graphql_client-0.4.3-py3-none-any.whl (4.9 kB)\n",
            "Collecting python-multipart<0.0.10,>=0.0.9 (from chainlit)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from chainlit)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting syncer<3.0.0,>=2.0.3 (from chainlit)\n",
            "  Downloading syncer-2.0.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit) (2.0.1)\n",
            "Collecting uptrace<2.0.0,>=1.22.0 (from chainlit)\n",
            "  Downloading uptrace-1.24.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting uvicorn<0.26.0,>=0.25.0 (from chainlit)\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles<0.21.0,>=0.20.0 (from chainlit)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chevron>=0.14.0 (from literalai==0.0.504->chainlit)\n",
            "  Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m119.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.26.0 (from auto-gptq)\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from auto-gptq)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Collecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting gekko (from auto-gptq)\n",
            "  Downloading gekko-1.1.1-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft>=0.5.0 (from auto-gptq)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit) (3.7.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting python-socketio>=4.6.0 (from fastapi-socketio<0.0.11,>=0.0.10->chainlit)\n",
            "  Downloading python_socketio-5.11.2-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->chainlit)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->chainlit)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2023.6.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Collecting websockets>=5.0 (from python-graphql-client<0.5.0,>=0.4.3->chainlit)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.2) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting opentelemetry-exporter-otlp~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit)\n",
            "  Downloading opentelemetry_exporter_otlp-1.24.0-py3-none-any.whl (7.0 kB)\n",
            "INFO: pip is looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.28.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn<0.26.0,>=0.25.0->chainlit)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn<0.26.0,>=0.25.0->chainlit)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->auto-gptq)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2.0.3)\n",
            "Collecting xxhash (from datasets->auto-gptq)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->auto-gptq)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit) (1.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.24.0 (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.24.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit)\n",
            "  Downloading python_engineio-4.9.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m?Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚??Å‚?\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: literalai, google-search-results, pypika, syncer\n",
            "  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for literalai: filename=literalai-0.0.504-py3-none-any.whl size=48976 sha256=4302a47df0c4719814b755ec81e53423a80999297590cec0a3122f0350517b71\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/fe/58/74c7e77fc1665a4b740320822a91761565528189e341659da1\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=9354834e67b5c384cec01cbdca380f7f50b8d635dc685271a9b4645d57bdae72\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=16263ff1e73b1b5f9deb0182a88e2ecbb7a6ef2c8ddff19ed441082fa1a2ef41\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syncer: filename=syncer-2.0.3-py2.py3-none-any.whl size=3436 sha256=21f379f43b4b6f37e11a3ae2d6133fc38d201b3a3866ab08825190cc39a7a342\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e4/36/bcaad665bcc2b672888ff2df1a5a1dc638378d8765055313cd\n",
            "Successfully built literalai google-search-results pypika syncer\n",
            "Installing collected packages: syncer, pypika, monotonic, mmh3, lazify, filetype, chevron, xxhash, websockets, uvloop, rouge, python-multipart, python-dotenv, pypdf, pyngrok, pyjwt, pulsar-client, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, gekko, dill, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, aiofiles, wsproto, watchfiles, uvicorn, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, marshmallow, jsonpatch, httpcore, google-search-results, coloredlogs, asyncer, simple-websocket, python-graphql-client, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, nvidia-cusolver-cu12, langsmith, kubernetes, httpx, fastapi, dataclasses-json, transformers, python-engineio, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, literalai, langchain-core, datasets, sentence-transformers, python-socketio, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp, langchain-text-splitters, langchain-community, accelerate, uptrace, peft, langchain, fastapi-socketio, chromadb, chainlit, auto-gptq\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 7.1.0\n",
            "    Uninstalling importlib_metadata-7.1.0:\n",
            "      Successfully uninstalled importlib_metadata-7.1.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed accelerate-0.29.3 aiofiles-23.2.1 asgiref-3.8.1 asyncer-0.0.2 auto-gptq-0.7.1 backoff-2.2.1 bcrypt-4.1.2 chainlit-1.0.504 chevron-0.14.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.5.14 datasets-2.18.0 deprecated-1.2.14 dill-0.3.8 fastapi-0.110.2 fastapi-socketio-0.0.10 filetype-1.2.0 gekko-1.1.1 google-search-results-2.4.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-7.0.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-29.0.0 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.49 lazify-0.4.0 literalai-0.0.504 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 multiprocess-0.70.16 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-exporter-otlp-proto-http-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.1 overrides-7.7.0 packaging-23.2 peft-0.10.0 posthog-3.5.0 pulsar-client-3.5.0 pyjwt-2.8.0 pyngrok-7.1.6 pypdf-4.2.0 pypika-0.48.9 python-dotenv-1.0.1 python-engineio-4.9.0 python-graphql-client-0.4.3 python-multipart-0.0.9 python-socketio-5.11.2 rouge-1.0.1 sentence-transformers-2.7.0 simple-websocket-1.0.0 starlette-0.37.2 syncer-2.0.3 transformers-4.37.2 typing-inspect-0.9.0 uptrace-1.24.0 uvicorn-0.25.0 uvloop-0.19.0 watchfiles-0.20.0 websockets-12.0 wsproto-1.2.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain chainlit pyngrok google-search-results transformers==4.37.2 pypdf sentence-transformers chromadb auto-gptq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import chainlit\n",
        "import pyngrok\n",
        "import transformers\n",
        "import pypdf\n",
        "import chromadb\n",
        "import auto_gptq\n",
        "\n",
        "\n",
        "print(langchain.__version__)\n",
        "print(chainlit.__version__)\n",
        "print(pyngrok.__version__)\n",
        "print(transformers.__version__)\n",
        "print(pypdf.__version__)\n",
        "print(chromadb.__version__)\n",
        "print(auto_gptq.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0BCfv-6Sx8a",
        "outputId": "e05334b8-ab37-4ac3-c478-6900c3b18438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1.16\n",
            "1.0.504\n",
            "7.1.6\n",
            "4.37.2\n",
            "4.2.0\n",
            "0.4.24\n",
            "0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from getpass import getpass\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import torch\n",
        "from langchain import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, TextStreamer\n",
        "from auto_gptq import AutoGPTQForCausalLM\n",
        "from langchain.agents import AgentOutputParser\n",
        "from langchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS\n",
        "from langchain.output_parsers.json import parse_json_markdown\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "I4svA2PqS0Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"Vector_db\"):\n",
        "  os.makedirs(\"Vector_db\")\n",
        "\n",
        "loader = PyPDFLoader(\"/content/e_budget_speech_2022-23.pdf\")\n",
        "data = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(data)\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "Vector_db_01 = Chroma.from_documents(docs, embeddings, collection_name=\"23budget\", persist_directory=\"Vector_db\")\n",
        "Vector_db_01.persist()\n",
        "Vector_db_01 = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "6034cbf860d94e77a1326240454bc362",
            "02fcf5e2ae2845b7a9dc52761c89107d",
            "b252c0118ee4427d9b1d75bc826ce7de",
            "ce1cd2560ae64dab9254f4a862a302bf",
            "3d29c6fda06d42ff87f735464c1679ff",
            "868675d4c1234105bc31711fb020fb6c",
            "eea175c3c65e48e2bd8963ab502f1e00",
            "9134bd4c43d64eb18f6144c6d409c2a7",
            "177ccd85dda040348fd0e017783d8357",
            "b6f17c5389524518b06e8279e91c1bc7",
            "09de5dbfe4da48cb906b5eb6eaffe3a5",
            "0fc75265920244ee896b59b99899420b",
            "60dcc2d380694201af15f3acdb542c14",
            "857a9bd0c36a40b2aedb8b76a2e867e5",
            "2240807cef464d9987df6812817b4449",
            "087f340ec80e451cb4bdc6bd3e1ba341",
            "2c66f767d4004ac088d90de5420978f8",
            "ead6a6be004f467a809b12aead71bc0b",
            "dbbd21ebff774654bfec1af5f6dd7e7c",
            "deb665d2cfe241cdb5390de9eff5a6cc",
            "ca3a76197dd94a3c9b947b4bb56d90a4",
            "43e0bc60946549e9994d68d0da39af4d",
            "5996eb9e35064282a1ab4147a3c13b9b",
            "1adfe57e92d146d6a10461d201fd1aab",
            "6383822fc630493baed9395603efbef8",
            "b3141696641b423b9915db8d9a1cfc5f",
            "791fefc3f4da4ef7b6e46fde16f092bc",
            "90b97c53225e452f8ab09ee651b8183e",
            "bcc9a0f2b73d46dbaabbff2c164c798b",
            "aedf14328a3e4b8483731b6632148f00",
            "4ab648ca38934d0195456ff4dbe6c72f",
            "41492513aa1441b1aa0365d90f2abfa5",
            "117ddf485e294b718d9dfea3a340fde1",
            "fc75291d199e48bca4bfde8e8836a393",
            "6bc85b09b642498b95f95627cd2afe6d",
            "02f45e02b71d4d4d89aed4001d714fdd",
            "5a24810540384a428f3bd90bcc88dcb5",
            "43513e3fd437461498e7e055fdd2b665",
            "889c987231b24aecb1057c67000711a3",
            "30c2b39133c34d2181c96d108d403369",
            "29200e75375d49e59ad95aa1669d3ee2",
            "1ab4b339023d4772be6ca8f16c9c4355",
            "4b700c96e7e6426db797679b7f8928de",
            "a73213a4f45640238117c9460fe073ef",
            "7b9451405a144f04bf0c7b326d7ccc05",
            "d0ee993602434a19957a85d6af010faf",
            "762fe5b72f7647f7879b2ed587d9fa3d",
            "fe7fe1d083f74cf295e64926fd1d783d",
            "8ce92b329f55439db0025c28949b11a2",
            "3ca4e3b7b6254ac2a0568b0bc6bcf3a2",
            "0a6782b0c1c349ba8491527a34b474cc",
            "e2728cb249504e90b996d936b351a7bb",
            "c92d546a6a3a40e79a18f80cd65c0c97",
            "3a0387b79c424af7bb69bf3e3600b90a",
            "d54b7e60bcce45f69a15daeb409356ea",
            "88f5eaf566db4efaa42149fe7ed38351",
            "a62ee1b3ed4e41cfb2da1c0cb07c5d86",
            "4f2309788f28403d8ffda38dec4fe62c",
            "a639f4f03d144b81803825905cb88637",
            "88927f872b1644dbbc5341ebafc3a0f6",
            "2fe2a5ee4fc64f36821b7f9361e60063",
            "de707b65503b4e0b9be207b381bd9dda",
            "f6cd0199177142b5ac42a2b9cb313016",
            "bfb448657dd84c06aa1c565755add569",
            "36404765b270414b96c35296ca8ef9e9",
            "690f35f67b4845929442f9ce68ef9334",
            "247afbeb9931430398dff383956f5f3e",
            "fda420feb8104270a5fa9b9065235417",
            "f33859ab4989482ea13871e59193b543",
            "7b2a567c65bb4f388415d45fc1b40f1d",
            "8482ae625c434f06b08af1be8d201be4",
            "806fd2e7c98d48cf993b9e9ccb0a28e0",
            "eca187a44d574fb1abbadbf0f6afd243",
            "4c5dc9c9366d497588e15f8213a040cb",
            "c86b61155da0442ca22558ca5b2f5a62",
            "f109b29c3f7e48d7938e33bd1f8c405c",
            "ddacf2ffe9814ae594c590540259e72e",
            "fd051d1736604f6f8f215012d9f6f298",
            "60f09a370b91401187aa0d1e93e10a33",
            "4476691239484ba7b5b26e3cf0da732f",
            "8a38141f94644a92b10ff9e56ad56fde",
            "724806338a484b6fbcd847b221bc600e",
            "813781047a974ede8b5d5ae95251487c",
            "3443ee266222445a901cc436a31bbef9",
            "b9a9cf53cbe842baa3ee7f5f152c5476",
            "bc7a117193254964a5fd977c52ec5afa",
            "4ff4d2c65b1b4fa685d472ee75ef5092",
            "d299d2c69a9d4e83a77668fb9c6277b3",
            "879f2b2e5a784e189d99005f946b2877",
            "46e9845d30f74195859c4c63181ed1f3",
            "0a33a59210de4927b95b0d991eaafadd",
            "f86abbf43dac46ee9e08fd75f86b8252",
            "44fd25b4b2a04aca83804001c3ab6b92",
            "f53922e52e4f451481a594de6e71671b",
            "6116eee12e7a4afc9ad8fa82fcdb7330",
            "c0617772fe7c4e82848dadff9567fe5a",
            "7d16d5a7aae04d7eb6cd39c00c3b72e1",
            "5c1c0a9fc57b43ceb948aeb62d9c085e",
            "4bf87740db3043a78d04f23a0bbc3da7",
            "e86231a96eb547b8876c62cc47a3bc2e",
            "a6a140c5448d4cba847fec1647603cad",
            "1997dcc016104a719d535138d6d0be7d",
            "92b6479d4f67421781aabc0774e940e9",
            "3505ab998c9649d8875325ccdac217e1",
            "eb0b60a3f6d94d38846d12ea4196f134",
            "7b79dc5fa51342cf8c87eb1aa7c68d54",
            "b44e56e7ee2b40e8b2850fbcff0f0cce",
            "b298ccd3f98d4b5da92d9381c1170342",
            "b754fa4875c64ecd879dde5978d5ffa5",
            "637e21e2a297493393e149a6d79d8764",
            "f2040a8d773d47ecb87474c6aa5b20d4",
            "968298d335b640958acd07e0583f5c79",
            "7fa01ab1dbb7461788fe4e50203fc766",
            "ef16473934b24678a9a3db6811a0fbe1",
            "f50d90cb2a1743aab541d6341c9eaa0b",
            "2824d42d83eb436383e2dc6e34a9b387",
            "c8b8634ccd2d4b06b68b5ac908901d09",
            "693aa16ee6e043c0b37c0d274efa978f",
            "e6dc605cfe234e588b67de52fe2ca0a6",
            "f9bfccbd80244dd3b552233cbb061acc",
            "a42535509a8e4919ba39f363169bb633"
          ]
        },
        "id": "itjt6mOpS3T4",
        "outputId": "d8afa607-b471-48bb-b3ef-181499d73227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6034cbf860d94e77a1326240454bc362"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fc75265920244ee896b59b99899420b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5996eb9e35064282a1ab4147a3c13b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc75291d199e48bca4bfde8e8836a393"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b9451405a144f04bf0c7b326d7ccc05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88f5eaf566db4efaa42149fe7ed38351"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "247afbeb9931430398dff383956f5f3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd051d1736604f6f8f215012d9f6f298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "879f2b2e5a784e189d99005f946b2877"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86231a96eb547b8876c62cc47a3bc2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2040a8d773d47ecb87474c6aa5b20d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vector_db_01 = Chroma(persist_directory=\"Vector_db\", collection_name=\"23budget\", embedding_function=embeddings)\n",
        "Vector_db_01.get()\n",
        "Vector_db_01.similarity_search(\"Is there any economic support for start up company in Hong Kong 2023 budget?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9wyYu19S8t4",
        "outputId": "2d4d81cd-188a-4f35-af7c-6ff68676ce0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Enhancing Economic Resilience and Enriching Industrial Development  \\n \\n \\n23 55. Over the past few years, apart from the $2  billion \\nInnovation and Technology Venture Fund, we have also set up the \\nCorporate Venture Fund and the Cyberport Macro Fund through the \\nHKSTPC and the Cyberport respectively.  Each of these funds has its own specific key areas of investment, which has significantly broadened the fundraising channel for start -ups in Hong Kong.  \\n56. Nevertheless, as the funds mentioned above are mainly \\ntargeted at early- stage start -ups, they may not be suitable for expanding \\nenterprises with considerable scale.  Some such type of enterprises \\noften have huge development potential.  Indeed, we are not short of \\nexamples of success in nurturing these enterprises in Hong Kong.  \\n57. I announced in my Budget two years ago the setting up of \\nan investment portfolio named the Hong Kong Growth Portfolio using part of the Future Fund for investment in projects with a ??Hong Kong \\nnexus ??  The aim is to consolidate Hong Kong?ôs status as a financial, \\ncommercial and I&T centre as well as to raise our productivity and \\ncompetitiveness in the long run.  Last year, the Government appointed \\neight fund managers as general partners to make strategic investment.  \\nTo nurture enterprises that are rel atively more mature and have good \\npotential for contribution to our economy, I will further increase the funding allocated to the Hong Kong Growth Portfolio under the Future \\nFund by $10 billion, of which $5 billion will be used to set up a new \\ninvestment f und, namely the Strategic Tech  Fund.  I will invite the \\nHKSTPC and the Cyberport to identify technology enterprises which \\nare of strategic value to Hong Kong as well as investment opportunities \\nconducive to enriching the I&T ecosystem.', metadata={'page': 29, 'source': '/content/e_budget_speech_2022-23.pdf'}),\n",
              " Document(page_content='Economic Outlook for 202 2 and Medium -term Outlook  \\n \\n \\n8 22. In the medium term, the economic outlook for  Hong Kong \\nis positive.  The sustained high- quality development of our country?ôs \\neconomy will serve as the key driver of global economic growth, and \\nprovide the most solid foundation for Hong Kong to prosper and \\ndevelop.  The 14th Five -Year Plan establishes a clear positioning and \\ndirection for Hong Kong?ôs economic  development and support s Hong \\nKong for  the development of the eight international centres and \\nemerging industries .  We may, by leveraging our advantages under \\n?úOne Country, Two Systems?? achieve co-ordinated development with \\nour neighbouring  cities in the Guangdong -Hong Kong- Macao Greater \\nBay Area (GBA), thereby creating enormous business opportunities and ample room for Hong Kong?ôs development.  Besides, the Government has been committed to nurturing emerging industries over \\nthe past few years.  Among them, the ecosystem of the innovation and \\ntechnology (I&T) industry has become increasingly mature and is ready to contribute more to Hong Kong?ôs economy and competitiveness in the coming few years.  Regarding our traditional industries, financial \\nservices  have been developing rapidly with a promising outlook, and \\nwill remain a driving force for our economic growth in future.  To make the best of the opportunities, we must continue to build capacity and overcome the constraints on our workforce and land supply, and \\nmake concerted efforts to scale new heights in our economic development.  Considering all these factors and taking into account the catch -up growth after the epidemic, I forecast that Hong K ong?ôs \\neconomy will grow by an average of three per  cent per annum in real \\nterms from 2023 to 2026, slightly higher than the trend growth of 2.8 per cent during  the decade before the pandemic.  The underlying \\ninflation rate is forecast to average 2.5  per cent.', metadata={'page': 14, 'source': '/content/e_budget_speech_2022-23.pdf'}),\n",
              " Document(page_content='Enhancing Economic Resilience and  Enriching Industrial Developm ent \\n \\n \\n46 Stepping up Investment Promotion \\n106. Foreign investment is highly conducive to the development \\nof various economic areas.  Quality foreign investment brings in not \\nonly c apital but also skills and job opportunities.  We must continue \\nto attract Mainland and overseas enterprises to make investment in Hong Kong, with a view to injecting new impetus into our economic growth.  \\n107. Hong Kong?ôs appeal to foreign investment is be yond \\nquestion.  According to a survey conducted by the Government, the number of Mainland and overseas companies in Hong Kong increased \\nby 10 per cent from 8  225 in 2017 to a record high of 9  049 last year, \\ndemonstrating that Hong Kong?ôs business environme nt remains \\nremarkable.  \\nAttract Investment from the Mainland and Overseas  \\n108. Competition among various economies in the aftermath of \\nthe pandemic will definitely intensify.  We must step up our efforts in \\ninvestment promotion to attract foreign enterprises to Hong Kong.  Starting from the next financial year, the Government will provide an \\nadditional recurrent provision of around $90 million in phases to \\nstrengthen InvestHK?ôs work and our investment promotion network in \\nthe Mainland and overseas.  \\n109. At present, Hong Kong has signed 45 Comprehensive \\nAvoidance of Double Taxation Agreements (CDTAs) and is in negotiations with 14  tax jurisdictions, with a view to minimising the \\nrisk of double taxation borne by foreign enterprises doing business in \\nHong Kong.   We will continue to proactively expand our CDTA \\nnetwork.', metadata={'page': 52, 'source': '/content/e_budget_speech_2022-23.pdf'}),\n",
              " Document(page_content='Enhancing Economic Resilience and Enriching Industrial Development  \\n \\n \\n51 Support Scheme for Pursuing Development in the Mainland  \\n118. To facilitate Hong Kong businessmen, professional \\nservices practitioners and entrepreneurs in the Mainland in better \\nintegrating into the overall development of our country  and seizing the \\nopportunities there, I will allocate a total funding of $135 million to the \\nTDC over the next three years for the introduction of the Support \\nScheme for Pursuing Development in the Mainland.  The scheme will \\nfocus on those Mainland cities with larger numbers of Hong Kong business people and workers, with priority accorded to the GBA.  \\nThrough the TDC?ôs network of offices in the Mainland, training and \\nexchange programmes, business missions as well as promotion activities will be organised in  partnership with various business \\nassociations to further support Hong Kong people in the Mainland, \\nincluding business chambers, professionals??groups and associations of \\nyoung entrepreneurs.', metadata={'page': 57, 'source': '/content/e_budget_speech_2022-23.pdf'})]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_llm_zephyr_7B():\n",
        "\n",
        "  model_name = \"TheBloke/zephyr-7B-beta-GPTQ\"\n",
        "  model_basename = \"model\"\n",
        "  revision=\"gptq-4bit-64g-actorder_True\"\n",
        "  DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "  model = AutoGPTQForCausalLM.from_quantized(\n",
        "      model_name,\n",
        "      revision=revision,\n",
        "      model_basename=model_basename,\n",
        "      use_safetensors=True,\n",
        "      trust_remote_code=True,\n",
        "      inject_fused_attention=False,\n",
        "      device=DEVICE,\n",
        "      quantize_config=None,)\n",
        "\n",
        "  streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "  text_pipeline = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=model,\n",
        "      tokenizer=tokenizer,\n",
        "      do_sample=False,\n",
        "      # temperature=0,\n",
        "      max_new_tokens=1024,\n",
        "      streamer=streamer,\n",
        "  )\n",
        "\n",
        "  llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "  return llm\n",
        "\n",
        "def set_prompt():\n",
        "\n",
        "  template = \"\"\"You are a helpful, respectful and honest assistant.\n",
        "          Answer the question in your own words as truthfully as possible from the context given to you.\n",
        "          If you do not know the answer to the question, simply respond with \"I don't know. Can you ask another question\".\n",
        "          If questions are asked where there is no relevant context available, simply respond with \"I don't know. Please ask a question relevant to the documents\"\n",
        "\n",
        "          Context: {context}\n",
        "\n",
        "          Human: {question}\n",
        "          Assistant:\"\"\"\n",
        "\n",
        "  zephyr_prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
        "\n",
        "  return zephyr_prompt\n",
        "\n",
        "def set_prompt_with_chat_history():\n",
        "\n",
        "  template = \"\"\"You are a helpful, respectful and honest assistant.\n",
        "          Answer the question in your own words as truthfully as possible from the context given to you.\n",
        "          If you do not know the answer to the question, simply respond with \"I don't know. Can you ask another question\".\n",
        "          If questions are asked where there is no relevant context available, simply respond with \"I don't know. Please ask a question relevant to the documents\"\n",
        "\n",
        "          Context: {context}\n",
        "\n",
        "\n",
        "          Chat history: {chat_history}\n",
        "\n",
        "          Human: {question}\n",
        "          Assistant:\"\"\"\n",
        "\n",
        "  zephyr_prompt = PromptTemplate( input_variables=[\"context\", \"chat_history\", \"question\"], template=template)\n",
        "\n",
        "  return zephyr_prompt\n",
        "\n",
        "def set_qa_chain():\n",
        "\n",
        "  memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\", output_key=\"answer\", return_messages=True)\n",
        "\n",
        "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "  Vector_db_01 = Chroma(persist_directory=\"Vector_db\", collection_name=\"23budget\", embedding_function=embeddings)\n",
        "  Vector_db_01.get()\n",
        "\n",
        "  llm = load_llm_zephyr_7B()\n",
        "  qa_chain_prompt = set_prompt_with_chat_history()\n",
        "\n",
        "\n",
        "  qa_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=Vector_db_01.as_retriever(),\n",
        "                            memory=memory, combine_docs_chain_kwargs={'prompt': qa_chain_prompt})\n",
        "\n",
        "  return qa_chain"
      ],
      "metadata": {
        "id": "Aem01XztS8x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_bot = set_qa_chain()\n",
        "\n",
        "qa_bot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519,
          "referenced_widgets": [
            "7300851523e44fa7be0eadabce3f9436",
            "0aea7ed4313d45cbb43313966f4352b9",
            "549536cc428b4a05b032fb16f68d90fe",
            "eb0ab6bd8c5a4623ac22a28f8730bffe",
            "ebaca517eceb4bd6a9b3742e2b9648ca",
            "81a32fd53d8f4e2c8314290a0dc312da",
            "05342e27f7934713bc14e4854c88e886",
            "f464853fd01e4065824b0999e81b6a1d",
            "ad7952e5b2a443ee86aa9ecdaee0a5a4",
            "a9d9ddba40a64a3faf16933b363610bb",
            "f2dd1f11e3f14592ad55caac8fdf01b3",
            "ac59ba872ab94c28bc979c5ceaa856c9",
            "c9be60ed568b4152a9f11e79d23b13e4",
            "948d38f79cdb4054ae4859b33eedcd54",
            "13b9ad8865ca43acb5049e2fcefe75f2",
            "dfb2fda5dd554b3b83a73882550d5d7f",
            "ed7acd284cb845409e149a2a1136b864",
            "99f5ffc935e24613832efcb303f2f8d1",
            "f53c2bfbe1bc4216ac758d4240b7e110",
            "b4bc859c9d1c448da34e1d50cbe00401",
            "85872bd7e44c4b0bb8b6fd43feaed67f",
            "3a48eea381144766be318ff3a89b41f6",
            "b8ae1b450d124c7cacbfc12ba969b79e",
            "4183e8a4167b4d70af62bfdef67bef3a",
            "b20ed0933b584427a0a4441594d4a2a2",
            "9333ee29bb414c46a7094bcb6e178be0",
            "b6cc2d3946dc44168f2f119a700fcdc9",
            "c8b4b6b1e974491b837df5e5c86ee32e",
            "2a3834d8f72b45a4816f6250246bf3d5",
            "10f09e0830534d85ac4ed7430c11bbf0",
            "1a52a662883b428d9c9ed216117aa9dc",
            "aaef108af67c4ec3b2659c4a5beb32f7",
            "157f30bed8cc4fa993f20a1fe4ce68c6",
            "33507ed9f91b47daa7d43a86ded066f5",
            "6c08d7f71bd04bb2a0f7799c9ebd88f6",
            "185a685b32c34477b64e726beeba6cfa",
            "7b67cf5d80cd4a008bb439ca4f630c38",
            "21aed3e078734dcab27e8f31204e59f3",
            "94fb71eafae64425b5c8cb2b82bd7b4e",
            "5b533d76355440fa89d61667f7dd8d3c",
            "392479cf2ca441e98e2fa55bb4bf0a4d",
            "338806523f1b4e7fb6ac5a3140065ba7",
            "5c01dbc0cd684090b6e95f7c6609754d",
            "d2353b2c86f742bc914a9c962815da11",
            "cebf6f89b6cb4e24a79ee22b411a31f0",
            "ec2e71e5b1dd499a85193143dc385ad2",
            "865ef5815b5a4b018abae2d38037c495",
            "d30c72265bdc455a8debd8eb5350f913",
            "6c03aaaa56414c0a9d111b1aaeed651b",
            "3c1b60fc47db47b0b4efde92f3bfc8b3",
            "a21262ea7a424dbb9f5a68a0ed0fdea9",
            "adf538025d1b42d085ca472174791ae7",
            "5f504ca4f9d344e693da090649376b77",
            "ea26a101445b486eb078108c7c49cc7d",
            "fd264a63a6ec4fffa9e7de6f2a00d2a2",
            "807a8d9c9dc84b3cb4001e82fa74bf5e",
            "3584e74828e64412badf8f148dc2eb18",
            "0daf1534f21f4ec6ae958c096178ca1f",
            "405bf5f3d444483db841523dba777c7d",
            "f29d891bf79a46bb90341e36d5d3d54a",
            "99dbf437c8824a72b0d76333eceacacb",
            "69cd4a09e66841f8aed1ac753941a3df",
            "ac3209e494164b548a8fee051430cfd7",
            "4352a1e1e462474892c523ac8d55ca11",
            "50368f0955c347659edc2f39dc010258",
            "f9f0ec42a44740309a225494e539f445",
            "78e8352d5e0e43bd81f825c0916dfd6f",
            "24c63d4a6c454e81879f3ace6563a5e8",
            "ed92ad0118664338b16317c9d46e5acf",
            "761916ac8ac646ce9b75edd2456c3ec0",
            "bc736e63b10e4dfbb88c55e631ce2968",
            "078da043f2d94004b884a215297895c1",
            "414898868432497a97dc6cb90d74f3d8",
            "c407b4ea2d9d47fd9d2302efb0a2aa84",
            "8296166fc29d41ca9a57fbc3b1d2aa72",
            "804b78b974c04b9f86b5534d168983c3",
            "5df59a5225d44e3cae2c83f0265dc7fe",
            "898c56c33e6f4eb495679ddac13aac47",
            "dba9e04cd81f4574b882458431d9ceea",
            "9b862ee55c0a46ab98bd9fb33e8584b7",
            "ff83daf583554dd9b3d808f36b9401c0",
            "213e8a5aa8074582bd159bbb7bd32e1b",
            "16622a0211304ea09a61ffa3068a5111",
            "7f5f76c2d8a24ef982fa82df8b38cd9b",
            "e96e3be7c6304ca78e3ff443061dd099",
            "83065425d9e14ee2a09a148f84d93ec4",
            "9f280ddf1a3a4189b1b7c44804220d05",
            "763a7c86d58747da87d2268264c965a0"
          ]
        },
        "id": "prYdeEKAS8z6",
        "outputId": "d0ac29eb-171b-4a7f-f8cc-e9faf4aa160b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7300851523e44fa7be0eadabce3f9436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac59ba872ab94c28bc979c5ceaa856c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8ae1b450d124c7cacbfc12ba969b79e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33507ed9f91b47daa7d43a86ded066f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cebf6f89b6cb4e24a79ee22b411a31f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "807a8d9c9dc84b3cb4001e82fa74bf5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "quantize_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78e8352d5e0e43bd81f825c0916dfd6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.29G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "898c56c33e6f4eb495679ddac13aac47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - The layer lm_head is not quantized.\n",
            "INFO:auto_gptq.modeling._base:The layer lm_head is not quantized.\n",
            "The model 'MistralGPTQForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationalRetrievalChain(memory=ConversationBufferMemory(output_key='answer', input_key='question', return_messages=True, memory_key='chat_history'), combine_docs_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['chat_history', 'context', 'question'], template='You are a helpful, respectful and honest assistant.\\n          Answer the question in your own words as truthfully as possible from the context given to you.\\n          If you do not know the answer to the question, simply respond with \"I don\\'t know. Can you ask another question\".\\n          If questions are asked where there is no relevant context available, simply respond with \"I don\\'t know. Please ask a question relevant to the documents\"\\n\\n          Context: {context}\\n\\n\\n          Chat history: {chat_history}\\n\\n          Human: {question}\\n          Assistant:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7859ac493eb0>, model_kwargs={'temperature': 0.1})), document_variable_name='context'), question_generator=LLMChain(prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7859ac493eb0>, model_kwargs={'temperature': 0.1})), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7859b1c07070>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDLaviyQiAmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Is there any economic support for start up company in Hong Kong 2023 budget?\"\n",
        "res = qa_bot.invoke({\"question\": query})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dix2dkFfhNyX",
        "outputId": "44694574-6a86-4eaf-bbe7-bdcb5b3d5979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, the Hong Kong Government has announced the setting up of a new investment fund, namely the Strategic Tech Fund, to nurture enterprises that are relatively more mature and have good potential for contribution to the economy. The Government will increase the funding allocated to the Hong Kong Growth Portfolio under the Future Fund by $10 billion, of which $5 billion will be used to set up the Strategic Tech Fund. The Hong Kong Science and Technology Parks Corporation (HKSTPC) and the Cyberport will be invited to identify technology enterprises which are of strategic value to Hong Kong as well as investment opportunities conducive to enriching the I&T ecosystem. This initiative aims to consolidate Hong Kong?ôs status as a financial, commercial, and I&T centre and raise its productivity and competitiveness in the long run.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = re.findall(r\"Assistant: (.*)\", res[\"answer\"])[-1].strip()\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SLf6_8EwhN0X",
        "outputId": "a7881c20-2de7-4c46-991e-cfa0f9261091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, the Hong Kong Government has announced the setting up of a new investment fund, namely the Strategic Tech Fund, to nurture enterprises that are relatively more mature and have good potential for contribution to the economy. The Government will increase the funding allocated to the Hong Kong Growth Portfolio under the Future Fund by $10 billion, of which $5 billion will be used to set up the Strategic Tech Fund. The Hong Kong Science and Technology Parks Corporation (HKSTPC) and the Cyberport will be invited to identify technology enterprises which are of strategic value to Hong Kong as well as investment opportunities conducive to enriching the I&T ecosystem. This initiative aims to consolidate Hong Kong?ôs status as a financial, commercial, and I&T centre and raise its productivity and competitiveness in the long run.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCThs7Sjh5vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Tell me about the $5 billion that you have mentioned.\"\n",
        "res = qa_bot.invoke({\"question\": query})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sHTzZQ6h-KO",
        "outputId": "86cc8056-af9d-4148-c7fe-63bbf10671f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How will the $5 billion allocated to the Strategic Tech Fund be used to support mature enterprises in Hong Kong?\n",
            "The $5 billion allocated to the Strategic Tech Fund will be used to support mature enterprises in Hong Kong that have significant development potential. The Hong Kong Science and Technology Parks Corporation (HKSTPC) and the Cyberport will be invited to identify technology enterprises which are of strategic value to Hong Kong as well as investment opportunities conducive to enriching the I&T ecosystem. This initiative aims to consolidate Hong Kong?ôs status as a financial, commercial, and I&T centre and raise its productivity and competitiveness in the long run.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = re.findall(r\"Assistant: (.*)\", res[\"answer\"])[-1].strip()\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "hRhEbDMPh5xh",
        "outputId": "55a776e5-32af-4b41-bd6b-7f64a40917a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The $5 billion allocated to the Strategic Tech Fund will be used to support mature enterprises in Hong Kong that have significant development potential. The Hong Kong Science and Technology Parks Corporation (HKSTPC) and the Cyberport will be invited to identify technology enterprises which are of strategic value to Hong Kong as well as investment opportunities conducive to enriching the I&T ecosystem. This initiative aims to consolidate Hong Kong?ôs status as a financial, commercial, and I&T centre and raise its productivity and competitiveness in the long run.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hHHAAzAi_Bm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}